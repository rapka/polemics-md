some TESCREALISts have attempted to smear the term as a conspiracy. this is ironic, becasue the mergig of sci-fi related cultures into the TESCREAL bundle we see today


Biden's executive order says this:
> The term “dual-use foundation model” means an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts; and that exhibits, or could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters, such as by:

> (i) substantially lowering the barrier of entry for non-experts to design, synthesize, acquire, or use chemical, biological, radiological, or nuclear (CBRN) weapons;
> (ii) enabling powerful offensive cyber operations through automated vulnerability discovery and exploitation against a wide range of potential targets of cyber attacks; or
> (iii) permitting the evasion of human control or oversight through means of deception or obfuscation.


af

> Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records regarding the following:
> any ongoing or planned activities related to training, developing, or producing dual-use foundation models
> this description shall include the results of any red-team testing that the company has conducted relating to lowering the barrier to entry for the development, acquisition, and use of biological weapons by non-state actors; the discovery of software vulnerabilities and development of associated exploits; the use of software or tools to influence real or virtual events; the possibility for self-replication or propagation; and associated measures to meet safety objectives;
> 

CSET's "[Skating to Where the Puck is Going](https://cset.georgetown.edu/publication/skating-to-where-the-puck-is-going/)" paper says this:
> he rise of LLMs has demonstrated that AI is becoming more general-purpose. Current systems are already capable of performing a wide range of distinct tasks, including translating text, writing and editing prose, solving math problems, writing software, and much more. However, there was broad consensus across roundtable participants that these systems are only one iteration of what are likely to be even more capable systems within the next few years. AI developers are actively working to make these systems more powerful, which in turn increases safety and security concerns. Five ways in which existing AI systems are currently being augmented are multimodality, tool use, deeper reasoning and planning, larger and more capable memory, and increased interaction between AI systems.
> In anticipation of new types of risks that current and upcoming models may pose, AI companies have begun undertaking “model evaluations” of their most advanced general-purpose AI models.  Such evaluations attempt to identify dangerous capabilities such as autonomous replication (a model’s ability to acquire resources, create copies of itself, and adapt to novel challenges); dangerous knowledge about sensitive subjects such as chemical, biological, radiological, or nuclear weapon production; capacity to carry out offensive cyber operations; the ability to manipulate, persuade, or deceive human observers; advanced cognitive capabilities such as long-term planning and error correction; and understanding of their own development, testing, and deployment (sometimes called situational awareness)

Let's comparing specific phrases in the EO with 
BIDEN:
> 
vs.
> advanced cognitive capabilities such as long-term planning and error correction; and understanding of their own development, testing, and deployment (sometimes called situational awareness)


BIDEN:
> substantially lowering the barrier of entry for non-experts to design, synthesize, acquire, or use chemical, biological, radiological, or nuclear (CBRN) weapons
vs.
OPENAI:
> dangerous knowledge about sensitive subjects such as chemical, biological, radiological, or nuclear weapon production

> enabling powerful offensive cyber operations through automated vulnerability discovery and exploitation against a wide range of potential targets of cyber attacks;
vs
> capacity to carry out offensive cyber operations

> permitting the evasion of human control or oversight through means of deception or obfuscation.
vs.
> the ability to manipulate, persuade, or deceive human observers

> The Secretary of Commerce shall require companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government...the results of any red-team testing that the company has conducted relating to...the possibility for self-replication or propagation
vs.
> dangerous capabilities such as autonomous replication (a model’s ability to acquire resources, create copies of itself, and adapt to novel challenges)

> a model shall be considered to have potential capabilities that could be used in malicious cyber-enabled activity if it requires a quantity of computing power greater than 1026 integer or floating-point operations and is trained on a computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum compute capacity of 1020 integer or floating-point operations per second for training AI.   


https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362

> CSET spokesperson Tessa Baker said that while Open Philanthropy remains its largest donor, it retains “complete and independent discretion over the research projects we conduct and the recommendations we make.” Baker also noted that some CSET researchers have emphasized a focus on AI’s real-world harms in addition to long-term risks.

...but one of their 

The Musk Connection

one of CSET's donors is the Musk Foundation. run by elon and his longtime fixer, the org donates to a wide variety of recipients, many of whom have no relation to any of his weird ad horrible ideas.

however, the wesbitet for the musk foundation only says this:




https://cset.georgetown.edu/wp-content/uploads/Frontier-AI-Roundtable-Paper-Final-2023CA004-v2.pdf